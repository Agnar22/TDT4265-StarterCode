{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a) {-}\n",
    "\n",
    "In the following figure, the predicted bounding box is given in red, while the true bounding box is given in blue. The area of intersection between the bounding boxes is given in black, while the union of the bounding boxes is the grey area + the black area. The intersection over union is now given as the area of intersection divided by the area of the union. (The black area /(black area + grey area))\n",
    "\n",
    "![](task1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b) {-}\n",
    "\n",
    "\\begin{equation}\n",
    "    Recall = \\frac{TP}{TP + FP}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    Precision = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "Where TP are the true positives, FP the false positive and FN the false negatives.\n",
    "A true postive is a correct prediction, while a false positive is when you predict the presence of an object, which actually is not there.\n",
    "\n",
    "## task 1c) {-}\n",
    "\n",
    "From the assignment we are given the following precision and recall levels for the two classes:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathrm{Class\\: 1:} \\\\\n",
    "    \\mathrm{Precision_1} &= \\left[1.0, 1.0, 1.0, 0.5, 0.20 \\right] \\\\\n",
    "    \\mathrm{Recall_1} &= \\left[0.05, 0.1, 0.4, 0.7, 1.0 \\right] \\\\\n",
    "\\end{align*}\n",
    "\\begin{align*}\n",
    "    \\mathrm{Class\\: 2:} \\\\\n",
    "    \\mathrm{Precision_2} &= \\left[1.0, 0.80, 0.60, 0.5, 0.20 \\right] \\\\\n",
    "    \\mathrm{Recall_2} &= \\left[0.3, 0.4, 0.5, 0.7, 1.0 \\right] \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The average precision, AP, is given by the following formula:\n",
    "\n",
    "\\begin{align*}\n",
    "    AP &= \\frac{1}{11} \\sum_{r \\in \\left\\{0, 0.1, ..., 1 \\right\\}} p_{interp}(r), \\\\\n",
    "    p_{interp}(r) &= \\max_{\\tilde{r}:\\tilde{r} \\geq r} p(\\tilde{r})\n",
    "\\end{align*}\n",
    "\n",
    "Using this formula, we get the following AP for the two classes:\n",
    "\n",
    "\\begin{align*}\n",
    "    AP_1 &= \\frac{1}{11} \\left(1 + 1 + 1 + 1 + 1 + 0.5 + 0.5 + 0.5 + 0.20 + 0.20 + 0.20 \\right) = 0.645 \\\\\n",
    "    AP_2 &= \\frac{1}{11} \\left(1 + 1 + 1 + 1 + 0.80 + 0.60 + 0.5 + 0.5 + 0.20 + 0.20 + 0.20 \\right) = 0.636\n",
    "\\end{align*}\n",
    "The mean average precision (mAP) is then the average AP over the classes, given mathematically by:\n",
    "\n",
    "\\begin{equation}\n",
    "    mAP = \\frac{1}{N} \\sum_{i=1}^N AP_i,\n",
    "\\end{equation}\n",
    "where $N$ is the number of classes and $i$ the class number. Using this we get the mAP as:\n",
    "\n",
    "\\begin{equation}\n",
    "    mAP = \\frac{1}{2} (0.645 + 0.636) = \\underline{0.641}\n",
    "\\end{equation}\n",
    "so the mAP for the two classes is 0.641\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 {-}\n",
    "\n",
    "### Task 2f) {-}\n",
    "\n",
    "![](task2/precision_recall_curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a) {-}\n",
    "The filter operation for overlapping boxes in SSD is called non-maximum suppression (nms).\n",
    "\n",
    "### Task 3b) {-}\n",
    "It is false. The deeper layers have lower resolution, which causes it to detect larger objects.\n",
    "\n",
    "### Task 3c) {-}\n",
    "Different bounding box aspect ratios are used, because there can be large interclass variations in the optimal bounding box aspect ratio, but small intraclass variations. By using different bounding box aspect ratios at the same spatial location, you are more likely to be able to detect different classes at the spatial location and not just optimize for a single class.\n",
    "\n",
    "\n",
    "### Task 3d) {-}\n",
    "The main difference is that SSD uses multiple convolutional layers at the end of the network to predict detections at difference scales, while the YOLO network uses a fully connected layer for this stage instead.\n",
    "\n",
    "### Task 3e) {-}\n",
    "for each layer, we have that the number of anchor boxes can be found by the following formula:\n",
    "\\begin{equation}\n",
    "    \\# boxes = H*W*(\\# defaultboxes)\n",
    "\\end{equation}\n",
    "\n",
    "Since we are given that $H=W=38$ and $\\# defaultboxes = 6$, we have that:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\# boxes = 38*38*6 = \\underline{8664},\n",
    "\\end{equation}\n",
    "so there are 8664 anchor boxes in total for this feature map.\n",
    "\n",
    "### Task 3f) {-}\n",
    "By using the formula in the preceding task and summming over each layer we get:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\# boxes_{total} = 38*38*6 + 19*19*6 + 10*10*6 + 5*5*6 + 3*3*6 + 1*1*6 = \\underline{11640},\n",
    "\\end{equation}\n",
    "\n",
    "so there are 11640 anchor boxes in total for the entire network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b) {-}\n",
    "\n",
    "(note: the yaml file used for this task is mnist.yaml)\n",
    "\n",
    "![](task4b_total_loss.png)\n",
    "\n",
    "The final mAP was 0.7870.\n",
    "\n",
    "## Task 4c) {-}\n",
    "\n",
    "(note: the yaml file used for this task is mnist_improved.yaml)\n",
    "\n",
    "The major improvements for this model were the same as the ones we found in assignment 3: use batch normalization with\n",
    "affine set to true, increase depth, use the adam optimizer, kernel size 3 and slightly increase size. Furthermore, tuning\n",
    "of hyper parameters to avoid over-fitting where essential: eg. learning rate and weight decay.\n",
    "The final mAP was 0.887.\n",
    "\n",
    "## Task 4d) {-}\n",
    "\n",
    "(note: the yaml file used for this task is mnist_best.yaml)\n",
    "\n",
    "![](90percent.png)\n",
    "\n",
    "The best mAP we achieved was 0.9040.\n",
    "\n",
    "\n",
    "## Task 4e) {-}\n",
    "\n",
    "![](0.png)\n",
    "\n",
    "![](1.png)\n",
    "\n",
    "![](2.png)\n",
    "\n",
    "![](3.png)\n",
    "\n",
    "![](4.png)\n",
    "\n",
    "![](5.png)\n",
    "\n",
    "![](6.png)\n",
    "\n",
    "![](7.png)\n",
    "\n",
    "![](8.png)\n",
    "\n",
    "![](9.png)\n",
    "\n",
    "The model had problem with '1', small numbers and numbers that were overlapping each other.\n",
    "\n",
    "\n",
    "## Task 4f) {-}\n",
    "![](task4f_total_loss.png)\n",
    "\n",
    "![](000342.png)\n",
    "\n",
    "![](000542.png)\n",
    "\n",
    "![](003123.png)\n",
    "\n",
    "![](004101.png)\n",
    "\n",
    "![](008591.png)\n",
    "\n",
    "The final mAP was 0.5112.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}